{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KoNLPy 의 Komoran 을 이용하여 라라랜드 영화 리뷰를 토크나이징 한 텍스트를 `lalaland_komoran.txt` 에, 원문을 `lalaland.txt` 에 저장하였습니다. 총 15,595 건의 영화평입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15595 15595\n"
     ]
    }
   ],
   "source": [
    "# Komoran tokenized La La Land review\n",
    "with open(r'C:\\Users\\user\\Desktop\\lalaland_komoran.txt', encoding='utf-8') as f:\n",
    "    sents = [sent.strip() for sent in f]\n",
    "\n",
    "with open(r'C:\\Users\\user\\Desktop\\lalaland.txt', encoding='utf-8') as f:\n",
    "    texts = [sent.strip() for sent in f]\n",
    "\n",
    "print(len(sents), len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextRank 에서는 word cooccurrence graph 를 만들 때 명사와 동사 등을 이용할 것을 제안하였습니다. 이는 조사나 관사와 같이 의미를 지니지 않으면서도 자주 이용되는 단어들이 높은 PageRank 를 가지게 되는 것을 방지하기 위해서입니다.\n",
    "\n",
    "Komoran 에서의 명사 (NN), 어근 (XR), 형용사 (VA), 동사 (VV) 만을 이용하여 word cooccurrence graph 를 만듭니다. window 를 -1 로 설정하면 한 문장에서 얼마나 떨어져 있던지 상관없이 cooccurrence 를 계산하며, window 가 1 보다 클 경우에는 해당 간격만큼만 떨어진 단어들 간에만 cooccurrence 를 인정합니다.\n",
    "\n",
    "학습 결과 `영화`, `음악`, `꿈`, `마지막` 같은 라라랜드의 엔딩을 의미하는 단어들이 핵심 단어로 선택되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화/NNG (1.73e+02)\n",
      "보/VV (1.29e+02)\n",
      "좋/VA (65.5)\n",
      "하/VV (52.0)\n",
      "것/NNB (47.4)\n",
      "같/VA (45.4)\n",
      "영화/NNP (43.8)\n",
      "음악/NNG (43.6)\n",
      "꿈/NNG (41.4)\n",
      "있/VV (40.8)\n",
      "없/VA (35.9)\n",
      "마지막/NNG (31.9)\n",
      "수/NNB (30.1)\n",
      "사랑/NNG (28.3)\n",
      "아름답/VA (26.5)\n",
      "현실/NNG (24.8)\n",
      "되/VV (23.9)\n",
      "노래/NNG (23.4)\n",
      "생각/NNG (23.2)\n",
      "스토리/NNP (21.4)\n",
      "번/NNB (20.3)\n",
      "거/NNB (19.7)\n",
      "최고/NNG (19.2)\n",
      "때/NNG (19.1)\n",
      "사람/NNG (19.0)\n",
      "여운/NNP (17.5)\n",
      "뮤지컬/NNP (16.9)\n",
      "나오/VV (16.5)\n",
      "듯/NNB (16.1)\n",
      "영상미/NNG (16.0)\n"
     ]
    }
   ],
   "source": [
    "from textrank import KeywordSummarizer\n",
    "\n",
    "def komoran_tokenize(sent):\n",
    "    words = sent.split()\n",
    "    words = [w for w in words if ('/NN' in w or '/XR' in w or '/VA' in w or '/VV' in w)]\n",
    "    return words\n",
    "\n",
    "keyword_extractor = KeywordSummarizer(\n",
    "    tokenize = komoran_tokenize,\n",
    "    window = -1,\n",
    "    verbose = False\n",
    ")\n",
    "keywords = keyword_extractor.summarize(sents, topk=30)\n",
    "for word, rank in keywords:\n",
    "    print('{} ({:.3})'.format(word, rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 모든 단어를 이용할 경우에는 조사 (JKG, JX, JKS, ... ) 어미 (EC, EP, ... ) 등이 핵심 단어로 선택됩니다. 이는 word cooccurrence graph 는 사실상 출현빈도가 높은 단어들이 높은 Rank 를 가지도록 유도하기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㄴ/ETM (1.24e+02)\n",
      "고/EC (1.03e+02)\n",
      "영화/NNG (96.8)\n",
      "는/ETM (94.6)\n",
      "이/VCP (92.3)\n",
      "이/JKS (92.0)\n",
      "하/XSV (85.2)\n",
      "에/JKB (79.0)\n",
      "았/EP (76.1)\n",
      "보/VV (73.5)\n",
      "었/EP (72.8)\n",
      "다/EC (68.3)\n",
      "을/JKO (64.2)\n",
      "하/XSA (58.8)\n",
      "의/JKG (58.4)\n",
      "도/JX (52.7)\n",
      "ㄹ/ETM (50.2)\n",
      "가/JKS (47.2)\n",
      "게/EC (46.7)\n",
      "는/JX (42.3)\n",
      "어/EC (37.9)\n",
      "좋/VA (37.6)\n",
      "를/JKO (34.3)\n",
      "아/EC (33.8)\n",
      "은/ETM (33.7)\n",
      "들/XSN (32.6)\n",
      "은/JX (32.0)\n",
      "하/VV (29.8)\n",
      "것/NNB (26.7)\n",
      "과/JC (26.5)\n"
     ]
    }
   ],
   "source": [
    "keyword_extractor = KeywordSummarizer(\n",
    "    tokenize=lambda x:x.split(),\n",
    "    verbose = False\n",
    ")\n",
    "keywords = keyword_extractor.summarize(sents, topk=30)\n",
    "for word, rank in keywords:\n",
    "    print('{} ({:.3})'.format(word, rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "window 의 크기를 바꾼다 하여도 큰 변화는 없습니다. 약간의 순위 변동은 있지만, 큰 맥락이 변하지는 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화/NNG (1.9e+02)\n",
      "보/VV (1.5e+02)\n",
      "좋/VA (80.8)\n",
      "하/VV (51.2)\n",
      "음악/NNG (50.8)\n",
      "영화/NNP (50.3)\n",
      "것/NNB (44.6)\n",
      "꿈/NNG (42.5)\n",
      "같/VA (40.7)\n",
      "있/VV (40.6)\n",
      "없/VA (35.5)\n",
      "마지막/NNG (33.7)\n",
      "아름답/VA (32.1)\n",
      "사랑/NNG (30.4)\n",
      "수/NNB (29.5)\n",
      "현실/NNG (27.9)\n",
      "노래/NNG (26.1)\n",
      "최고/NNG (23.8)\n",
      "스토리/NNP (23.6)\n",
      "생각/NNG (23.5)\n",
      "되/VV (23.1)\n",
      "번/NNB (22.7)\n",
      "여운/NNP (22.1)\n",
      "감동/NNG (19.1)\n",
      "사람/NNG (18.6)\n",
      "때/NNG (18.0)\n",
      "거/NNB (18.0)\n",
      "지루/XR (17.6)\n",
      "영상미/NNG (16.8)\n",
      "재밌/VA (16.3)\n"
     ]
    }
   ],
   "source": [
    "keyword_extractor = KeywordSummarizer(\n",
    "    tokenize = komoran_tokenize,\n",
    "    window = 2,\n",
    "    verbose = False\n",
    ")\n",
    "keywords = keyword_extractor.summarize(sents, topk=30)\n",
    "for word, rank in keywords:\n",
    "    print('{} ({:.3})'.format(word, rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "핵심 문장을 선택하기 위하여 문장 간 유사도를 계산한 다음, `min_sim` 이상의 유사도를 지니는 문장 간에 adjacent sentence graph 를 만듭니다. 그리고 여기에 PageRank 를 적용하여 핵심 문장을 선택합니다.\n",
    "\n",
    "텍스트를 출력할 때에는 토크나이징된 문장은 가독이 어렵기 때문에 원 텍스트를 이용하여 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating textrank sentence similarity was done with 15595 sents\n",
      "trained TextRank. n sentences = 15595\n",
      "#5861 (6.12) : 사랑에 대해 다시 한 번 생각해 볼 수 있게 하는 영화인 것 같습니다 장면 처리도 좋았어요 여운이 많이 남는 영화입니다 꼭 보세요\n",
      "\n",
      "#5947 (5.8) : 아 진짜 평점 처음 써본다 진짜 후회 안할 영화 나중에 다시 봐도 좋을것 같다 오프닝에서 신나는 노래부터 마지막의 상상 하는 씬까지 너무 좋음 결말이 여운이 있다고 해야하나 슬프다고 해야하나 꿈얘기 할때 현실성 있어서 눈물날뻔 결말이짱\n",
      "\n",
      "#5076 (5.69) : 옛날 영화같은 느낌의 기법 사람을 행복하게 만드는 음악 약간의 촌스러움이 마음을 간지를 수 있는 지극히 현실적인 사랑과 꿈이야기를 로맨틱하게 풀어낸 영화로 연말 영화로 보기 좋은 것 같아요\n",
      "\n",
      "#6665 (5.41) : 인생영화다 노래도 너무 좋고 배우 소품 배경 장면들 하나하나 맘에 안 드는게 없다 ㅠㅠ 특히 마지막 셉oo에서의 내용은 진짜 잊을 수가 없을 거같다 보고나면 먹먹하고 안타까운 느낌이 드는데 그래도 황홀하고 아름다운 영화다\n",
      "\n",
      "#9271 (5.28) : 연출 음악 영상미 엔딩은 정말 좋았다 마지막에 남녀주인공이 나눈 눈빛이 아직도 잊혀지지않을만큼 여운이 남는 영화였다 초중반 약간 지루하긴했었다 배우들 춤연습을 많이한게보였음 꿈 성공 과 사랑을 다 가질수 없다는것을 현실적으로보여준 영화가아니었나싶다\n",
      "\n",
      "#13909 (5.12) : 인생 최고의 영화 또보고싶다 영상미 음악 스토리 다 좋아요\n",
      "\n",
      "#5922 (4.99) : 정말 영상미랑 음악은 최고였다 그리고 신선했다 음악이 너무 멋있어서 연기를 봐야 할지 노래를 들어야 할지 모를 정도로 그리고 보고 나서 생각 좀 많아진 영화 정말 이 연말에 보기 좋은 영화 인 것 같다\n",
      "\n",
      "#11408 (4.88) : 진짜 그냥 좋았던 영화 두번봐도 재밌을영화\n",
      "\n",
      "#12362 (4.88) : 보고 난 후 그냥 인생영화 다 라는 말밖에 안나오는 영화다 너무나도 아름다운 색감과 영상미 우리가 꿈꾸는 판타지 로맨스를 그대로 옮겨놓은 듯 하다 영화관을 나와도 귀에 맴도는 음악을 들으며 하늘에 있는 별들을 바라보며 집으로 올수밖에 없었다\n",
      "\n",
      "#187 (4.88) : 저가 본 영화중에서 두번째로 최고인 영화였던것같습니다 노래도너무좋았고 정말 한 장면도 놓칠수없었습니다 재밌었고 앞으로도 이런 비슷한 영화들이나와도 괜찮을것같다 싶었던것같습니다\n",
      "\n",
      "#2082 (4.84) : 뮤지컬영화 처음봐서 처음엔 이게 뭐지 싶었는데 노래가 영화를 얼마나 풍성하게 할 수 있는지 몸소 느꼈다 꿈을 향한 두 남녀의 여정과 사랑이 너무 아름다웠다 참 여운이 남는 영화\n",
      "\n",
      "#14711 (4.84) : 제 인생 최고의 뮤지컬 영화라고 자신있게 말할수 있어요 ㅜ ㅜ 또 보러 갈 예정 음악도 전부 좋고 엔딩크래딧 다 올라갈때까지 자리에서 여윤 때문에 못일어났네요 정말 아름다운 영화였어요 여운이 기네요\n",
      "\n",
      "#980 (4.77) : 좋은 영화다여운이 남고 마지막 장면은 눈물을 참을 수가 없었다 슬픈 눈물이 아닌 아름다운 것을 봤을 때 흘리는 눈물이런 기분이구나\n",
      "\n",
      "#5220 (4.72) : 음악 미술 연기 등 모든 것이 좋았지만 마지막 결말이 너무 현실에 뒤떨어진 꿈만 같다 꿈을 이야기하는 영화지만 과정과 결과에 있어 예술가들의 현실을 너무 반영하지 못한 것이 아닌가하는 생각이든다 그래서 보고 난 뒤 나는 꿈을 꿔야하는데 허탈했다\n",
      "\n",
      "#3099 (4.72) : 세 번째 관람 음악도 좋고 색감도 너무 이뻐요꿈에 대해 생각해 보게 하는 영화\n",
      "\n",
      "#8087 (4.7) : 조금 이해못했었는데 해석을 보니까 다 이해가 되더라고요 꿈과 사랑에 대해서 잘 표현한것 같았어요 이해하니까 여운이 많이 남았어요 노래도 되게 좋았고요 연기도 최고 2016년 말을 장식하는 최고의 영화에요 굿굿\n",
      "\n",
      "#7461 (4.69) : 인생영화가 아니라 인생 최악의 영화 영상미는 좋았지만 싸우는 장면 빼곤 지루하기 짝이 없음 결말도 너무나 어이없었음 평점 후기 보고 기대했는데 어떻게 내 생각과 이렇게 반대일 수 있는지 시간 돈이 아까웠다\n",
      "\n",
      "#10282 (4.63) : 여운 많이 남는 최고의 영화 영상미도 너무 아름답고 보는 내내 가슴이 벅차올랐다 재즈 음악이 많이 들리던 것도 너무 좋다 또 보러갈 예정\n",
      "\n",
      "#583 (4.61) : 눈이 호강하네요 음악도 좋구요 그러나 위플래쉬때와 같이 보고 나면 마음속에 남는것이 하나도 없습니다 음악영화이나 너무 보여주기식으로만 영화를 만드는것이 이 감독의 특징인 것 같습니다\n",
      "\n",
      "#9175 (4.6) : 너무 좋은 영화에요 꼭 보세요\n",
      "\n",
      "#11283 (4.6) : 아주 좋은 영화를 봤습니다\n",
      "\n",
      "#1929 (4.6) : 두고두고 계속 볼 영화 너무나 좋았습니다\n",
      "\n",
      "#2165 (4.6) : 너무 좋았어요 다시 보고싶은 영화에요\n",
      "\n",
      "#6068 (4.6) : 그냥 너랑 봐서 좋았던 영화\n",
      "\n",
      "#11603 (4.6) : 좋은 영화였습니다 또보고싶어요\n",
      "\n",
      "#1242 (4.6) : 정말 좋은 영화였어요 꼭 보세요\n",
      "\n",
      "#3869 (4.59) : 정말 너무 영화 잘 봤습니다 근래들어 본 영화중에 제일 감동 음악도 너무 좋고 배우들도 너무 멋있습니다 마지막 둘의 눈빛 잊을 수가 없네요\n",
      "\n",
      "#7059 (4.57) : 사실 두번째 보는 영화입니다 영상 편집과 음악이 너무 좋아요 어떻게 보면 너무나 현실적일 수 있는 결말이 슬프기하지만 아름답습니다\n",
      "\n",
      "#4033 (4.57) : 다른 분들에 비해 저는 조금 지루하긴 했는데 영상미는 끝내주는 것 같아요 음악도 영화 볼 때보다 보고나서 티비나 거리에서 들려오면 영화생각 나면서 더 좋은 듯\n",
      "\n",
      "#4357 (4.56) : 세번 봤어요 이동진 평론가 평 보고 다시 보니까 처음 봤을 때 말로 표현할 수 없던 감정들이 정리가 되는 느낌이어서 더 좋았어요 사랑영화이기도 하면서 성장영화이기도 한 라라랜드 인생영화에요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textrank import KeysentenceSummarizer\n",
    "\n",
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = komoran_tokenize,\n",
    "    min_sim = 0.5,\n",
    "    verbose = True\n",
    ")\n",
    "keysents = summarizer.summarize(sents)\n",
    "for idx, rank, komoran_sent in keysents:\n",
    "    print('#{} ({:.3}) : {}'.format(idx, rank, texts[idx]), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 뉴스 기사에 대하여 3 개의 핵심 문장을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "    '오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다',\n",
    "    '서울 연합뉴스 김은경 기자 사제 총기로 경찰을 살해한 범인 성모 46 씨는 주도면밀했다',\n",
    "    '경찰에 따르면 성씨는 19일 오후 강북경찰서 인근 부동산 업소 밖에서 부동산업자 이모 67 씨가 나오기를 기다렸다 이씨와는 평소에도 말다툼을 자주 한 것으로 알려졌다',\n",
    "    '이씨가 나와 걷기 시작하자 성씨는 따라가면서 미리 준비해온 사제 총기를 이씨에게 발사했다 총알이 빗나가면서 이씨는 도망갔다 그 빗나간 총알은 지나가던 행인 71 씨의 배를 스쳤다',\n",
    "    '성씨는 강북서 인근 치킨집까지 이씨 뒤를 쫓으며 실랑이하다 쓰러뜨린 후 총기와 함께 가져온 망치로 이씨 머리를 때렸다',\n",
    "    '이 과정에서 오후 6시 20분께 강북구 번동 길 위에서 사람들이 싸우고 있다 총소리가 났다 는 등의 신고가 여러건 들어왔다',\n",
    "    '5분 후에 성씨의 전자발찌가 훼손됐다는 신고가 보호관찰소 시스템을 통해 들어왔다 성범죄자로 전자발찌를 차고 있던 성씨는 부엌칼로 직접 자신의 발찌를 끊었다',\n",
    "    '용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기',\n",
    "    '신고를 받고 번동파출소에서 김창호 54 경위 등 경찰들이 오후 6시 29분께 현장으로 출동했다 성씨는 그사이 부동산 앞에 놓아뒀던 가방을 챙겨 오패산 쪽으로 도망간 후였다',\n",
    "    '김 경위는 오패산 터널 입구 오른쪽의 급경사에서 성씨에게 접근하다가 오후 6시 33분께 풀숲에 숨은 성씨가 허공에 난사한 10여발의 총알 중 일부를 왼쪽 어깨 뒷부분에 맞고 쓰러졌다',\n",
    "    '김 경위는 구급차가 도착했을 때 이미 의식이 없었고 심폐소생술을 하며 병원으로 옮겨졌으나 총알이 폐를 훼손해 오후 7시 40분께 사망했다',\n",
    "    '김 경위는 외근용 조끼를 입고 있었으나 총알을 막기에는 역부족이었다',\n",
    "    '머리에 부상을 입은 이씨도 함께 병원으로 이송됐으나 생명에는 지장이 없는 것으로 알려졌다',\n",
    "    '성씨는 오패산 터널 밑쪽 숲에서 오후 6시 45분께 잡혔다',\n",
    "    '총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다',\n",
    "    '총 때문에 쫓던 경관들과 민간인들이 몸을 숨겼는데 인근 신발가게 직원 이모씨가 다가가 성씨를 덮쳤고 이어 현장에 있던 다른 상인들과 경찰이 가세해 체포했다',\n",
    "    '성씨는 경찰에 붙잡힌 직후 나 자살하려고 한 거다 맞아 죽어도 괜찮다 고 말한 것으로 전해졌다',\n",
    "    '성씨 자신도 경찰이 발사한 공포탄 1발 실탄 3발 중 실탄 1발을 배에 맞았으나 방탄조끼를 입은 상태여서 부상하지는 않았다',\n",
    "    '경찰은 인근을 수색해 성씨가 만든 사제총 16정과 칼 7개를 압수했다 실제 폭발할지는 알 수 없는 요구르트병에 무언가를 채워두고 심지를 꽂은 사제 폭탄도 발견됐다',\n",
    "    '일부는 숲에서 발견됐고 일부는 성씨가 소지한 가방 안에 있었다'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "띄어쓰기 기준으로 adjacent sentence graph 를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다\n",
      "총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다\n",
      "용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기\n"
     ]
    }
   ],
   "source": [
    "from textrank import KeysentenceSummarizer\n",
    "\n",
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = lambda x:x.split(),\n",
    "    min_sim = 0.3,\n",
    "    verbose = False\n",
    ")\n",
    "keysents = summarizer.summarize(sents, topk=3)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KoNLPy 의 Komoran 을 이용하여 토크나이징과 핵심문장을 한 번에 추출하는 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다\n",
      "용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기\n",
      "신고를 받고 번동파출소에서 김창호 54 경위 등 경찰들이 오후 6시 29분께 현장으로 출동했다 성씨는 그사이 부동산 앞에 놓아뒀던 가방을 챙겨 오패산 쪽으로 도망간 후였다\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "def komoran_tokenizer(sent):\n",
    "    words = komoran.pos(sent, join=True)\n",
    "    words = [w for w in words if ('/NN' in w or '/XR' in w or '/VA' in w or '/VV' in w)]\n",
    "    return words\n",
    "\n",
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = komoran_tokenizer,\n",
    "    min_sim = 0.3,\n",
    "    verbose = False\n",
    ")\n",
    "keysents = summarizer.summarize(sents, topk=3)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 위의 결과를 얻기 위해서는 토크나이저도 제대로 구축할 필요가 없습니다. 어자피 많이 등장한 단어라면 해당 단어를 구성하는 부분어절 (subword) 역시 자주 등장하였을 것이며, 이를 이용한 문장 간 유사도를 측정하여도 비슷하기 때문입니다.\n",
    "\n",
    "아래는 띄어쓰기 기준으로 나뉘어진 어절에서 3음절의 subwords 를 잘라내는 토크나이저 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이것은',\n",
       " '부분단',\n",
       " '분단어',\n",
       " '단어의',\n",
       " '예시입',\n",
       " '시입니',\n",
       " '입니다',\n",
       " '짧은',\n",
       " '어절은',\n",
       " '그대로',\n",
       " '나옵니',\n",
       " '옵니다']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def subword_tokenizer(sent, n=3):\n",
    "    def subword(token, n):\n",
    "        if len(token) <= n:\n",
    "            return [token]\n",
    "        return [token[i:i+n] for i in range(len(token) - n + 1)]\n",
    "    return [sub for token in sent.split() for sub in subword(token, n)]\n",
    "\n",
    "subword_tokenizer('이것은 부분단어의 예시입니다 짧은 어절은 그대로 나옵니다')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 이용하여도 핵심 문장은 위와 동일하게 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다\n",
      "용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기\n",
      "총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다\n"
     ]
    }
   ],
   "source": [
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = subword_tokenizer,\n",
    "    min_sim = 0.3,\n",
    "    verbose = False\n",
    ")\n",
    "keysents = summarizer.summarize(sents, topk=3)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summarizer 의 R 에는 각 문장 별 중요도 (PageRank 값) 가 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.76438621, 0.74969733, 1.33782296, 0.61722741, 0.7377122 ,\n",
       "       1.07534516, 0.62928904, 1.71145208, 1.07601036, 1.13590053,\n",
       "       0.94446938, 0.67686714, 0.7008805 , 1.02103025, 1.61461996,\n",
       "       0.76911158, 0.78024047, 0.65793743, 1.02927478, 0.97072522])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장의 위치에 따라 중요도를 다르게 설정할 수도 있습니다. 뉴스 기사는 대부분 첫 문장이 중요합니다. 실제로 위의 예시에서도 첫 문장이 가장 중요한 핵심 문장으로 선택되었습니다. 만약 마지막 문장이 중요하다고 가정한다면 이러한 정보를 bias 에 추가할 수 있습니다. numpy.ndarray 형태로 bias 를 만듭니다. 마지막 문장이 다른 문장보다 10 배 중요하다고 가정하였습니다. 이를 summarize 함수의 bias 에 입력하면 가장 먼저 맨 마지막 문장이 중요한 문장으로 선택됩니다. 다른 문장들 중에서도 맨 마지막 문장과 비슷할수록 상대적인 중요도가 더 커집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일부는 숲에서 발견됐고 일부는 성씨가 소지한 가방 안에 있었다\n",
      "경찰은 인근을 수색해 성씨가 만든 사제총 16정과 칼 7개를 압수했다 실제 폭발할지는 알 수 없는 요구르트병에 무언가를 채워두고 심지를 꽂은 사제 폭탄도 발견됐다\n",
      "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bias = np.ones(len(sents))\n",
    "bias[-1] = 10\n",
    "\n",
    "keysents = summarizer.summarize(sents, topk=3, bias=bias)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R 을 다시 확인해보면 PageRank 값이 달라졌음을 확인할 수 있습니다. 상대적인 위치 외에도 특정 단어가 포함된 문장에 preference (bias) 를 더 높게 설정할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.22183954, 0.51902092, 0.92584783, 0.42671701, 0.50982682,\n",
       "       0.74430683, 0.43498201, 1.18547126, 0.74505343, 0.78632222,\n",
       "       0.65347844, 0.46802437, 0.48465947, 0.70684359, 1.11845189,\n",
       "       0.53125081, 0.53956034, 0.45476333, 3.14941282, 4.39416707])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting summa\n",
      "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
      "Requirement already satisfied: scipy>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from summa) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scipy>=0.19->summa) (1.20.1)\n",
      "Building wheels for collected packages: summa\n",
      "  Building wheel for summa (setup.py): started\n",
      "  Building wheel for summa (setup.py): finished with status 'done'\n",
      "  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54415 sha256=9301310b127c97551aaeca0788e76866c4dbd5f7a9f42c44cfac9d2cb02f8028\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\fd\\6a\\dd\\209eb19d5f2266b9cfd06827539bf70435b0ad5fe8244e52d3\n",
      "Successfully built summa\n",
      "Installing collected packages: summa\n",
      "Successfully installed summa-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Automatic summarization is the process of reducing a text document with a \\\n",
    "computer program in order to create a summary that retains the most important points \\\n",
    "of the original document. As the problem of information overload has grown, and as \\\n",
    "the quantity of data has increased, so has interest in automatic summarization. \\\n",
    "Technologies that can make a coherent summary take into account variables such as \\\n",
    "length, writing style and syntax. An example of the use of summarization technology \\\n",
    "is search engines such as Google. Document summarization is another.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic summarization is the process of reducing a text document with a computer program in order to create a summary that retains the most important points of the original document.\n"
     ]
    }
   ],
   "source": [
    "from summa import summarizer\n",
    "print(summarizer.summarize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "summarization\n",
      "writing\n",
      "account\n"
     ]
    }
   ],
   "source": [
    "from summa import keywords\n",
    "print(keywords.keywords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Automatic summarization is the process of reducing a text document with a computer program in order to create a summary that retains the most important points of the original document.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from summa.summarizer import summarize\n",
    "summarize(text, ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Automatic summarization is the process of reducing a text document with a computer program in order to create a summary that retains the most important points of the original document.\\nAn example of the use of summarization technology is search engines such as Google.\\nDocument summarization is another.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(text, words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Automatic summarization is the process of reducing a text document with a computer program in order to create a summary that retains the most important points of the original document.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(text, split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    " \n",
    "def read_article(file_name):\n",
    "    file = open(file_name, \"r\",encoding='utf8')\n",
    "    filedata = file.readlines()\n",
    "    article = filedata[0].split(\". \")\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in article:\n",
    "        print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop() \n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    " \n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def generate_summary(file_name, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "\n",
    "    # Step 1 - Read text anc split it\n",
    "    sentences =  read_article(file_name)\n",
    "\n",
    "    # Step 2 - Generate Similary Martix across sentences\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "\n",
    "    # Step 3 - Rank sentences in similarity martix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "    # Step 4 - Sort the rank and pick top sentences\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "\n",
    "    # Step 5 - Offcourse, output the summarize texr\n",
    "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub which has been launched to empower the next generation of students with AI-ready skills\n",
      "Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100 institutions with AI infrastructure, course content and curriculum, developer support, development tools and give students access to cloud and AI services\n",
      "As part of the program, the Redmond giant which wants to expand its reach and is planning to build a strong developer ecosystem in India with the program will set up the core AI infrastructure and IoT Hub for the selected campuses\n",
      "The company will provide AI development tools and Azure AI services such as Microsoft Cognitive Services, Bot Services and Azure Machine Learning.According to Manish Prakash, Country General Manager-PS, Health and Education, Microsoft India, said, \"With AI being the defining technology of our time, it is transforming lives and industry and the jobs of tomorrow will require a different skillset\n",
      "This will require more collaborations and training and working with AI\n",
      "That’s why it has become more critical than ever for educational institutions to integrate new cloud and AI technologies\n",
      "The program is an attempt to ramp up the institutional set-up and build capabilities among the educators to educate the workforce of tomorrow.\" The program aims to build up the cognitive skills and in-depth understanding of developing intelligent cloud connected solutions for applications across industry\n",
      "Earlier in April this year, the company announced Microsoft Professional Program In AI as a learning track open to the public\n",
      "The program was developed to provide job ready skills to programmers who wanted to hone their skills in AI and data science with a series of online courses which featured hands-on labs and expert instructors as well\n",
      "This program also included developer-focused AI school that provided a bunch of assets to help build AI skills.\n",
      "\n",
      "Indexes of top ranked_sentence order are  [(0.15083257041122708, ['Envisioned', 'as', 'a', 'three-year', 'collaborative', 'program,', 'Intelligent', 'Cloud', 'Hub', 'will', 'support', 'around', '100', 'institutions', 'with', 'AI', 'infrastructure,', 'course', 'content', 'and', 'curriculum,', 'developer', 'support,', 'development', 'tools', 'and', 'give', 'students', 'access', 'to', 'cloud', 'and', 'AI', 'services']), (0.13161201335715553, ['The', 'company', 'will', 'provide', 'AI', 'development', 'tools', 'and', 'Azure', 'AI', 'services', 'such', 'as', 'Microsoft', 'Cognitive', 'Services,', 'Bot', 'Services', 'and', 'Azure', 'Machine', 'Learning.According', 'to', 'Manish', 'Prakash,', 'Country', 'General', 'Manager-PS,', 'Health', 'and', 'Education,', 'Microsoft', 'India,', 'said,', '\"With', 'AI', 'being', 'the', 'defining', 'technology', 'of', 'our', 'time,', 'it', 'is', 'transforming', 'lives', 'and', 'industry', 'and', 'the', 'jobs', 'of', 'tomorrow', 'will', 'require', 'a', 'different', 'skillset']), (0.11403047674961146, ['Earlier', 'in', 'April', 'this', 'year,', 'the', 'company', 'announced', 'Microsoft', 'Professional', 'Program', 'In', 'AI', 'as', 'a', 'learning', 'track', 'open', 'to', 'the', 'public']), (0.10721749759953528, ['In', 'an', 'attempt', 'to', 'build', 'an', 'AI-ready', 'workforce,', 'Microsoft', 'announced', 'Intelligent', 'Cloud', 'Hub', 'which', 'has', 'been', 'launched', 'to', 'empower', 'the', 'next', 'generation', 'of', 'students', 'with', 'AI-ready', 'skills']), (0.10404298514456578, ['As', 'part', 'of', 'the', 'program,', 'the', 'Redmond', 'giant', 'which', 'wants', 'to', 'expand', 'its', 'reach', 'and', 'is', 'planning', 'to', 'build', 'a', 'strong', 'developer', 'ecosystem', 'in', 'India', 'with', 'the', 'program', 'will', 'set', 'up', 'the', 'core', 'AI', 'infrastructure', 'and', 'IoT', 'Hub', 'for', 'the', 'selected', 'campuses']), (0.10031366655994461, ['That’s', 'why', 'it', 'has', 'become', 'more', 'critical', 'than', 'ever', 'for', 'educational', 'institutions', 'to', 'integrate', 'new', 'cloud', 'and', 'AI', 'technologies']), (0.10001137283486655, ['The', 'program', 'is', 'an', 'attempt', 'to', 'ramp', 'up', 'the', 'institutional', 'set-up', 'and', 'build', 'capabilities', 'among', 'the', 'educators', 'to', 'educate', 'the', 'workforce', 'of', 'tomorrow.\"', 'The', 'program', 'aims', 'to', 'build', 'up', 'the', 'cognitive', 'skills', 'and', 'in-depth', 'understanding', 'of', 'developing', 'intelligent', 'cloud', 'connected', 'solutions', 'for', 'applications', 'across', 'industry']), (0.09916750119894317, ['This', 'will', 'require', 'more', 'collaborations', 'and', 'training', 'and', 'working', 'with', 'AI']), (0.09277191614415067, ['The', 'program', 'was', 'developed', 'to', 'provide', 'job', 'ready', 'skills', 'to', 'programmers', 'who', 'wanted', 'to', 'hone', 'their', 'skills', 'in', 'AI', 'and', 'data', 'science', 'with', 'a', 'series', 'of', 'online', 'courses', 'which', 'featured', 'hands-on', 'labs', 'and', 'expert', 'instructors', 'as', 'well'])]\n",
      "Summarize Text: \n",
      " Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100 institutions with AI infrastructure, course content and curriculum, developer support, development tools and give students access to cloud and AI services. The company will provide AI development tools and Azure AI services such as Microsoft Cognitive Services, Bot Services and Azure Machine Learning.According to Manish Prakash, Country General Manager-PS, Health and Education, Microsoft India, said, \"With AI being the defining technology of our time, it is transforming lives and industry and the jobs of tomorrow will require a different skillset. Earlier in April this year, the company announced Microsoft Professional Program In AI as a learning track open to the public\n"
     ]
    }
   ],
   "source": [
    "# let's begin\n",
    "generate_summary(r'C:\\Users\\user\\Desktop\\ai.txt', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nThose Who Are Resilient Stay In The Game Longer *\\n“On the mountains of truth you can never climb in vain: either you will reach a point higher up today, or you will be training your powers so that you will be able to climb higher tomorrow.” — Friedrich Nietzsche\\nChallenges and setbacks are not meant to defeat you, but promote you.', 'To be honest, I don’t have the answers.', 'To a person with a Fixed Mindset failure is a blow to their self-esteem, yet to a person with a Growth Mindset, it’s an opportunity to improve and find new ways to overcome their obstacles.', 'However, it’s important not to be discouraged by failure when pursuing a goal or a dream, since failure itself means different things to different people.', 'However, I realise after many years of defeats, it can crush your spirit and it is easier to give up than risk further setbacks and disappointments.']\n",
      "['\\nThose Who Are Resilient Stay In The Game Longer *\\n“On the mountains of truth you can never climb in vain: either you will reach a point higher up today, or you will be training your powers so that you will be able to climb higher tomorrow.” — Friedrich Nietzsche\\nChallenges and setbacks are not meant to defeat you, but promote you.', 'To be honest, I don’t have the answers.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.cluster.util import cosine_distance\n",
    "\n",
    "MULTIPLE_WHITESPACE_PATTERN = re.compile(r\"\\s+\", re.UNICODE)\n",
    "\n",
    "\n",
    "def normalize_whitespace(text):\n",
    "    \"\"\"\n",
    "    Translates multiple whitespace into single space character.\n",
    "    If there is at least one new line character chunk is replaced\n",
    "    by single LF (Unix new line) character.\n",
    "    \"\"\"\n",
    "    return MULTIPLE_WHITESPACE_PATTERN.sub(_replace_whitespace, text)\n",
    "\n",
    "\n",
    "def _replace_whitespace(match):\n",
    "    text = match.group()\n",
    "\n",
    "    if \"\\n\" in text or \"\\r\" in text:\n",
    "        return \"\\n\"\n",
    "    else:\n",
    "        return \" \"\n",
    "\n",
    "\n",
    "def is_blank(string):\n",
    "    \"\"\"\n",
    "    Returns `True` if string contains only white-space characters\n",
    "    or is empty. Otherwise `False` is returned.\n",
    "    \"\"\"\n",
    "    return not string or string.isspace()\n",
    "\n",
    "\n",
    "def get_symmetric_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Get Symmetric matrix\n",
    "    :param matrix:\n",
    "    :return: matrix\n",
    "    \"\"\"\n",
    "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
    "\n",
    "\n",
    "def core_cosine_similarity(vector1, vector2):\n",
    "    \"\"\"\n",
    "    measure cosine similarity between two vectors\n",
    "    :param vector1:\n",
    "    :param vector2:\n",
    "    :return: 0 < cosine similarity value < 1\n",
    "    \"\"\"\n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    "\n",
    "\n",
    "'''\n",
    "Note: This is not a summarization algorithm. This Algorithm pics top sentences irrespective of the order they appeared.\n",
    "'''\n",
    "\n",
    "\n",
    "class TextRank4Sentences():\n",
    "    def __init__(self):\n",
    "        self.damping = 0.85  # damping coefficient, usually is .85\n",
    "        self.min_diff = 1e-5  # convergence threshold\n",
    "        self.steps = 100  # iteration steps\n",
    "        self.text_str = None\n",
    "        self.sentences = None\n",
    "        self.pr_vector = None\n",
    "\n",
    "    def _sentence_similarity(self, sent1, sent2, stopwords=None):\n",
    "        if stopwords is None:\n",
    "            stopwords = []\n",
    "\n",
    "        sent1 = [w.lower() for w in sent1]\n",
    "        sent2 = [w.lower() for w in sent2]\n",
    "\n",
    "        all_words = list(set(sent1 + sent2))\n",
    "\n",
    "        vector1 = [0] * len(all_words)\n",
    "        vector2 = [0] * len(all_words)\n",
    "\n",
    "        # build the vector for the first sentence\n",
    "        for w in sent1:\n",
    "            if w in stopwords:\n",
    "                continue\n",
    "            vector1[all_words.index(w)] += 1\n",
    "\n",
    "        # build the vector for the second sentence\n",
    "        for w in sent2:\n",
    "            if w in stopwords:\n",
    "                continue\n",
    "            vector2[all_words.index(w)] += 1\n",
    "\n",
    "        return core_cosine_similarity(vector1, vector2)\n",
    "\n",
    "    def _build_similarity_matrix(self, sentences, stopwords=None):\n",
    "        # create an empty similarity matrix\n",
    "        sm = np.zeros([len(sentences), len(sentences)])\n",
    "\n",
    "        for idx1 in range(len(sentences)):\n",
    "            for idx2 in range(len(sentences)):\n",
    "                if idx1 == idx2:\n",
    "                    continue\n",
    "\n",
    "                sm[idx1][idx2] = self._sentence_similarity(sentences[idx1], sentences[idx2], stopwords=stopwords)\n",
    "\n",
    "        # Get Symmeric matrix\n",
    "        sm = get_symmetric_matrix(sm)\n",
    "\n",
    "        # Normalize matrix by column\n",
    "        norm = np.sum(sm, axis=0)\n",
    "        sm_norm = np.divide(sm, norm, where=norm != 0)  # this is ignore the 0 element in norm\n",
    "\n",
    "        return sm_norm\n",
    "\n",
    "    def _run_page_rank(self, similarity_matrix):\n",
    "\n",
    "        pr_vector = np.array([1] * len(similarity_matrix))\n",
    "\n",
    "        # Iteration\n",
    "        previous_pr = 0\n",
    "        for epoch in range(self.steps):\n",
    "            pr_vector = (1 - self.damping) + self.damping * np.matmul(similarity_matrix, pr_vector)\n",
    "            if abs(previous_pr - sum(pr_vector)) < self.min_diff:\n",
    "                break\n",
    "            else:\n",
    "                previous_pr = sum(pr_vector)\n",
    "\n",
    "        return pr_vector\n",
    "\n",
    "    def _get_sentence(self, index):\n",
    "\n",
    "        try:\n",
    "            return self.sentences[index]\n",
    "        except IndexError:\n",
    "            return \"\"\n",
    "\n",
    "    def get_top_sentences(self, number=5):\n",
    "\n",
    "        top_sentences = []\n",
    "\n",
    "        if self.pr_vector is not None:\n",
    "\n",
    "            sorted_pr = np.argsort(self.pr_vector)\n",
    "            sorted_pr = list(sorted_pr)\n",
    "            sorted_pr.reverse()\n",
    "\n",
    "            index = 0\n",
    "            for epoch in range(number):\n",
    "                sent = self.sentences[sorted_pr[index]]\n",
    "                sent = normalize_whitespace(sent)\n",
    "                top_sentences.append(sent)\n",
    "                index += 1\n",
    "\n",
    "        return top_sentences\n",
    "\n",
    "    def analyze(self, text, stop_words=None):\n",
    "        self.text_str = text\n",
    "        self.sentences = sent_tokenize(self.text_str)\n",
    "\n",
    "        tokenized_sentences = [word_tokenize(sent) for sent in self.sentences]\n",
    "\n",
    "        similarity_matrix = self._build_similarity_matrix(tokenized_sentences, stop_words)\n",
    "\n",
    "        self.pr_vector = self._run_page_rank(similarity_matrix)\n",
    "\n",
    "\n",
    "text_str = '''\n",
    "    Those Who Are Resilient Stay In The Game Longer *\n",
    "    “On the mountains of truth you can never climb in vain: either you will reach a point higher up today, or you will be training your powers so that you will be able to climb higher tomorrow.” — Friedrich Nietzsche\n",
    "    Challenges and setbacks are not meant to defeat you, but promote you. However, I realise after many years of defeats, it can crush your spirit and it is easier to give up than risk further setbacks and disappointments. Have you experienced this before? To be honest, I don’t have the answers. I can’t tell you what the right course of action is; only you will know. However, it’s important not to be discouraged by failure when pursuing a goal or a dream, since failure itself means different things to different people. To a person with a Fixed Mindset failure is a blow to their self-esteem, yet to a person with a Growth Mindset, it’s an opportunity to improve and find new ways to overcome their obstacles. Same failure, yet different responses. Who is right and who is wrong? Neither. Each person has a different mindset that decides their outcome. Those who are resilient stay in the game longer and draw on their inner means to succeed.\n",
    "    '''\n",
    "\n",
    "tr4sh = TextRank4Sentences()\n",
    "tr4sh.analyze(text_str)\n",
    "print(tr4sh.get_top_sentences(5))\n",
    "\n",
    "print(tr4sh.get_top_sentences(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'konlpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-140b282efb6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# pip3 install newspaper3k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnewspaper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mArticle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKkma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTwitter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'konlpy'"
     ]
    }
   ],
   "source": [
    "# pip3 install newspaper3k\n",
    "from newspaper import Article\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma()\n",
    "        self.twitter = Twitter()\n",
    "        self.stopwords = ['중인' ,'만큼', '마찬가지', '꼬집었', \"연합뉴스\", \"데일리\", \"동아일보\", \"중앙일보\", \"조선일보\", \"기자\",                           \n",
    "        \"아\", \"휴\", \"아이구\", \"아이쿠\", \"아이고\", \"어\", \"나\", \"우리\", \"저희\", \"따라\", \"의해\", \"을\", \"를\", \"에\", \"의\", \"가\",]\n",
    "    \n",
    "    def url2sentences(self, url):\n",
    "        article = Article(url, language='ko')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        sentences = self.kkma.sentences(article.text)\n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        return sentences\n",
    "    \n",
    "    def text2sentences(self, text):\n",
    "        sentences = self.kkma.sentences(text)\n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        return sentences\n",
    "    \n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence != '':\n",
    "                nouns.append(' '.join([noun for noun in self.twitter.nouns(str(sentence))\\\n",
    "                                       if noun not in self.stopwords and len(noun) > 1]))\n",
    "        return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "        \n",
    "    def build_sent_graph(self, sentence):\n",
    "        tfidf_mat = self.tfidf.fit_transform(sentence).toarray()\n",
    "        self.graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n",
    "        return self.graph_sentence\n",
    "\n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rank(object):\n",
    "    def get_ranks(self, graph, d=0.85): # d = damping factor\n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 # diagonal 부분을 0으로\n",
    "            link_sum = np.sum(A[:,id]) # A[:, id] = A[:][id]\n",
    "        if link_sum != 0:\n",
    "            A[:, id] /= link_sum\n",
    "        A[:, id] *= -d\n",
    "        A[id, id] = 1\n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) # 연립방정식 Ax = b\n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank(object):\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "        if text[:5] in ('http:', 'https'):\n",
    "            self.sentences = self.sent_tokenize.url2sentences(text)\n",
    "        else:\n",
    "            self.sentences = self.sent_tokenize.text2sentences(text)\n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "        self.rank = Rank()\n",
    "        self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
    "        self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "        \n",
    "    def summarize(self, sent_num=3):\n",
    "        summary = []\n",
    "        index=[]\n",
    "        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
    "            index.append(idx)\n",
    "        index.sort()\n",
    "        for idx in index:\n",
    "            summary.append(self.sentences[idx])\n",
    "        return summary\n",
    "    \n",
    "    def keywords(self, word_num=10):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "        keywords = []\n",
    "        index=[]\n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "        #index.sort()\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "        return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://v.media.daum.net/v/20170611192209012?rcmd=r'\n",
    "textrank = TextRank(url)\n",
    "for row in textrank.summarize(3):\n",
    "    print(row)\n",
    "    print()\n",
    "    print('keywords :',textrank.keywords())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from urllib.request import urlretrieve, urlopen\n",
    "import gzip\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"glove.6B.zip\")\n",
    "zf = zipfile.ZipFile('glove.6B.zip')\n",
    "zf.extractall() \n",
    "zf.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "glove_dict = dict()\n",
    "f = open('glove.6B.100d.txt', encoding=\"utf8\") # 100차원의 GloVe 벡터를 사용\n",
    "\n",
    "for line in f:\n",
    "    word_vector = line.split()\n",
    "    word = word_vector[0]\n",
    "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32') # 100개의 값을 가지는 array로 변환\n",
    "    glove_dict[word] = word_vector_arr\n",
    "f.close()\n",
    "'''\n",
    "# glove_dict['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300차원의 FastText 벡터 사용\n",
    "import fasttext.util\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.get_word_vector('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300차원의 Word2Vec 벡터 사용\n",
    "urlretrieve(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", \\\n",
    "                           filename=\"GoogleNews-vectors-negative300.bin.gz\")\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "zero_vector = np.zeros(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 벡터의 평균으로부터 문장 벡터를 얻는다.\n",
    "def calculate_sentence_vector(sentence):\n",
    "    return sum([glove_dict.get(word, zero_vector) \n",
    "                  for word in sentence])/len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sent = ['I', 'am', 'a', 'student']\n",
    "sentence_vector = calculate_sentence_vector(eng_sent)\n",
    "print(len(sentence_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 사용하고 있는 사전 훈련된 GloVe는 영어에 대해서 학습된 임베딩입니다. \n",
    "# 그래서 한국어를 넣으면 당연히 모든 단어에 대해서 OOV 문제가 발생합니다. \n",
    "# 즉, 모든 단어가 영벡터이므로 평균을 구해도 영벡터가 반환됩니다. 실제로 값을 확인해봅시다.\n",
    "\n",
    "kor_sent = ['전', '좋은', '학생', '입니다']\n",
    "sentence_vector = calculate_sentence_vector(kor_sent)\n",
    "print(sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlretrieve(\"https://raw.githubusercontent.com/prateekjoshi565/textrank_text_summarization/master/tennis_articles_v4.csv\", filename=\"tennis_articles_v4.csv\")\n",
    "data = pd.read_csv(\"tennis_articles_v4.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['article_text']]\n",
    "data['sentences'] = data['article_text'].apply(sent_tokenize)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 함수\n",
    "def tokenization(sentences):\n",
    "    return [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  # 영어를 제외한 숫자, 특수 문자 등은 전부 제거. 모든 알파벳은 소문자화\n",
    "  sentence = [re.sub(r'[^a-zA-z\\s]', '', word).lower() for word in sentence]\n",
    "  # 불용어가 아니면서 단어가 실제로 존재해야 한다.\n",
    "  return [word for word in sentence if word not in stop_words and word]\n",
    "\n",
    "# 위 전처리 함수를 모든 문장에 대해서 수행. 이 함수를 호출하면 모든 행에 대해서 수행.\n",
    "def preprocess_sentences(sentences):\n",
    "    return [preprocess_sentence(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized_sentences'] = data['sentences'].apply(tokenization)\n",
    "data['tokenized_sentences'] = data['tokenized_sentences'].apply(preprocess_sentences)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "zero_vector = np.zeros(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 벡터의 평균으로부터 문장 벡터를 얻는다.\n",
    "def calculate_sentence_vector(sentence):\n",
    "    if len(sentence) != 0:\n",
    "        return sum([glove_dict.get(word, zero_vector) for word in sentence])/len(sentence)\n",
    "    else:\n",
    "        return zero_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장에 대해서 문장 벡터를 반환\n",
    "def sentences_to_vectors(sentences):\n",
    "    return [calculate_sentence_vector(sentence) \n",
    "              for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SentenceEmbedding'] = data['tokenized_sentences'].apply(sentences_to_vectors)\n",
    "data[['SentenceEmbedding']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(sentence_embedding):\n",
    "    sim_mat = np.zeros([len(sentence_embedding), len(sentence_embedding)])\n",
    "    for i in range(len(sentence_embedding)):\n",
    "        for j in range(len(sentence_embedding)):\n",
    "            sim_mat[i][j] = cosine_similarity(sentence_embedding[i].reshape(1, embedding_dim),\n",
    "                                          sentence_embedding[j].reshape(1, embedding_dim))[0,0]\n",
    "    return sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SimMatrix'] = data['SentenceEmbedding'].apply(similarity_matrix)\n",
    "data['SimMatrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('두번째 샘플의 문장 개수 :',len(data['tokenized_sentences'][1]))\n",
    "print('두번째 샘플의 문장 벡터가 모인 문장 행렬의 크기(shape) :',np.shape(data['SentenceEmbedding'][1]))\n",
    "print('두번째 샘플의 유사도 행렬의 크기(shape) :',data['SimMatrix'][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graphs(sim_matrix):\n",
    "    nx_graph = nx.from_numpy_array(sim_matrix)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    pos = nx.spring_layout(nx_graph)\n",
    "    nx.draw(nx_graph, with_labels=True, font_weight='bold')\n",
    "    nx.draw_networkx_edge_labels(nx_graph,pos,font_color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graphs(data['SimMatrix'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(sim_matrix):\n",
    "    nx_graph = nx.from_numpy_array(sim_matrix)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['score'] = data['SimMatrix'].apply(calculate_score)\n",
    "data[['SimMatrix', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['score'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranked_sentences(sentences, scores, n=3):\n",
    "    top_scores = sorted(((scores[i],s) \n",
    "                         for i,s in enumerate(sentences)), \n",
    "                                reverse=True)\n",
    "    top_n_sentences = [sentence \n",
    "                        for score,sentence in top_scores[:n]]\n",
    "    return \" \".join(top_n_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['summary'] = data.apply(lambda x: \n",
    "                            ranked_sentences(x.sentences, \n",
    "                            x.score), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(data)):\n",
    "    print(i+1,'번 문서')\n",
    "    print('원문 :',data.loc[i].article_text)\n",
    "    print('')\n",
    "    print('요약 :',data.loc[i].summary)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple (AAPL) has unveiled the latest version of iOS, dubbed iOS 15. The company revealed the update on Monday during its virtual Worldwide Developers Conference 2021, or WWDC.\n",
      "\n",
      "The changes to the operating system that powers millions of iPhones around the world include new notification settings, improvements to Messages, changes to Photos, and more. Here are the biggest changes coming to your iPhone with iOS 15.\n",
      "\n",
      "Big changes to FaceTime\n",
      "\n",
      "The FaceTime app is getting an overhaul to make video chats feel more natural for users by adding spatial audio, which allows audio to sound like it's coming from the direction in which a speaker is positioned in a call. If they're on the left, the sound will sound like it's coming from the left, and vice versa.\n",
      "\n",
      "The company is also adding a feature that focuses specifically on your voice, blocking out background noise, as well as a means to take in even more of the sound around you. The new FaceTime Links option lets you plan a FaceTime call via Calendar invites or share links via text messages. The company is even allowing users without iOS devices to join FaceTime chats via web links, which Apple says will be encrypted just as they are on the iPhone or iPad.\n",
      "\n",
      "Apple also debuted a new feature called SharePlay that lets you bring music and shows into your FaceTime calls, allowing you to listen and watch with friends and family. Shared controls will also let anyone in the call pause and play whatever you're listening to or watching. You'll also be able to watch shows via iOS's picture-in-picture mode or you can extend them to your TV via AirPlay.\n",
      "\n",
      "Apple's iOS 15 is bringing big changes to the iPhone. (Apple)\n",
      "\n",
      "Apple says SharePlay will work with Disney+. Twitch, Hulu, TikTok, ESPN+, and other services. Then there's a new screen sharing feature that lets you literally share what you're seeing on your screen with your friends, so you can show them what you're looking at online, or give them a hand with a quick instructional walkthrough if you're having trouble using an app.\n",
      "\n",
      "Story continues\n",
      "\n",
      "Messages and Notification updates\n",
      "\n",
      "Messages, meanwhile, is getting updates in the form of a feature called Shared with You, that allows you to view all of the news articles, and videos your friends have shared with you over time in your Messages, rather than losing them amidst your stream of back and forth texts.\n",
      "\n",
      "The Photos app is also getting a Shared with You section to see photos that friends have shared with you. Apple says the only photos that will appear in your Photos app will be those that include your face, to prevent your library from becoming cluttered with screenshots and memes.\n",
      "\n",
      "Notifications in iOS are also getting updates with improved icons and a feature called Notification summary. This will allow you to schedule when certain notifications appear and are ordered by priority. Notifications from people won't be in the summary, though, to make sure you still get messages the moment they're sent your way.\n",
      "\n",
      "There's also a Do Not Disturb mode for Messages that will let people know that you're not taking texts at the moment, whether you're in a meeting or having dinner. Of course, people can still cut in by calling or alerting you that it's important.\n",
      "\n",
      "There's also a new focus mode that allows you to set certain notifications for things like work or when you're out of the office. If you're at work, for example, only notifications for work apps will come through. Out of the office, you'll get notifications for non-work apps.\n",
      "\n",
      "Live Text, Photos, and more\n",
      "\n",
      "A new Live Text feature can now capture text from photos and paste them as text directly into emails or other apps. If you see a phone number in a shot, you can tap it and call it. Apple is also adding object recognition for photos, so they'll be able to identify pets and landmarks. It's something similar to Google's own Google Lens, though Google has years of experience behind its app, so it will be interesting to see how Live Text stacks up.\n",
      "\n",
      "On the Photos side of things, there are changes to Memories that allows you to customize the look and audio behind your memories, with Apple pulling songs from its Apple Music library.\n",
      "\n",
      "Apple has also announced that it will soon allow you to put your ID in your Apple Wallet. That means, in certain states, you'll be able to use your Apple Wallet to present your license. That's a major change, and goes along nicely with the ability to use your Apple Wallet to show your car insurance when you get pulled over.\n",
      "\n",
      "Sign up for Yahoo Finance Tech newsletter\n",
      "\n",
      "Got a tip? Email Daniel Howley at dhowley@yahoofinance.com over via encrypted mail at danielphowley@protonmail.com, and follow him on Twitter at @DanielHowley.\n",
      "\n",
      "More from Dan:\n",
      "\n",
      "Follow Yahoo Finance on Twitter, Facebook, Instagram, Flipboard, SmartNews, LinkedIn, YouTube, and reddit.\n"
     ]
    }
   ],
   "source": [
    "# !pip install gensim newspaper3k\n",
    "# !pip install gensim==3.8.1\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from newspaper import Article\n",
    "\n",
    "url = \"https://finance.yahoo.com/news/apple-ios-15-debut-174727899.html\"\n",
    "news = Article(url, language='en')\n",
    "news.download()\n",
    "news.parse()\n",
    "print(news.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The changes to the operating system that powers millions of iPhones around the world include new notification settings, improvements to Messages, changes to Photos, and more.\n",
      "The FaceTime app is getting an overhaul to make video chats feel more natural for users by adding spatial audio, which allows audio to sound like it's coming from the direction in which a speaker is positioned in a call.\n",
      "The company is even allowing users without iOS devices to join FaceTime chats via web links, which Apple says will be encrypted just as they are on the iPhone or iPad.\n",
      "Apple also debuted a new feature called SharePlay that lets you bring music and shows into your FaceTime calls, allowing you to listen and watch with friends and family.\n",
      "Apple's iOS 15 is bringing big changes to the iPhone.\n",
      "Then there's a new screen sharing feature that lets you literally share what you're seeing on your screen with your friends, so you can show them what you're looking at online, or give them a hand with a quick instructional walkthrough if you're having trouble using an app.\n",
      "Messages, meanwhile, is getting updates in the form of a feature called Shared with You, that allows you to view all of the news articles, and videos your friends have shared with you over time in your Messages, rather than losing them amidst your stream of back and forth texts.\n",
      "There's also a new focus mode that allows you to set certain notifications for things like work or when you're out of the office.\n",
      "A new Live Text feature can now capture text from photos and paste them as text directly into emails or other apps.\n"
     ]
    }
   ],
   "source": [
    "# 기본 요약\n",
    "print(summarize(news.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The changes to the operating system that powers millions of iPhones around the world include new notification settings, improvements to Messages, changes to Photos, and more.\n",
      "Here are the biggest changes coming to your iPhone with iOS 15.\n",
      "The FaceTime app is getting an overhaul to make video chats feel more natural for users by adding spatial audio, which allows audio to sound like it's coming from the direction in which a speaker is positioned in a call.\n",
      "The new FaceTime Links option lets you plan a FaceTime call via Calendar invites or share links via text messages.\n",
      "The company is even allowing users without iOS devices to join FaceTime chats via web links, which Apple says will be encrypted just as they are on the iPhone or iPad.\n",
      "Apple also debuted a new feature called SharePlay that lets you bring music and shows into your FaceTime calls, allowing you to listen and watch with friends and family.\n",
      "Apple's iOS 15 is bringing big changes to the iPhone.\n",
      "Then there's a new screen sharing feature that lets you literally share what you're seeing on your screen with your friends, so you can show them what you're looking at online, or give them a hand with a quick instructional walkthrough if you're having trouble using an app.\n",
      "Messages, meanwhile, is getting updates in the form of a feature called Shared with You, that allows you to view all of the news articles, and videos your friends have shared with you over time in your Messages, rather than losing them amidst your stream of back and forth texts.\n",
      "The Photos app is also getting a Shared with You section to see photos that friends have shared with you.\n",
      "Apple says the only photos that will appear in your Photos app will be those that include your face, to prevent your library from becoming cluttered with screenshots and memes.\n",
      "Notifications in iOS are also getting updates with improved icons and a feature called Notification summary.\n",
      "There's also a Do Not Disturb mode for Messages that will let people know that you're not taking texts at the moment, whether you're in a meeting or having dinner.\n",
      "There's also a new focus mode that allows you to set certain notifications for things like work or when you're out of the office.\n",
      "If you're at work, for example, only notifications for work apps will come through.\n",
      "Out of the office, you'll get notifications for non-work apps.\n",
      "A new Live Text feature can now capture text from photos and paste them as text directly into emails or other apps.\n",
      "Apple is also adding object recognition for photos, so they'll be able to identify pets and landmarks.\n",
      "On the Photos side of things, there are changes to Memories that allows you to customize the look and audio behind your memories, with Apple pulling songs from its Apple Music library.\n",
      "That means, in certain states, you'll be able to use your Apple Wallet to present your license.\n"
     ]
    }
   ],
   "source": [
    "# 출력단어 500개로 제한\n",
    "print(summarize(news.text, word_count=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The FaceTime app is getting an overhaul to make video chats feel more natural for users by adding spatial audio, which allows audio to sound like it's coming from the direction in which a speaker is positioned in a call.\n",
      "The company is even allowing users without iOS devices to join FaceTime chats via web links, which Apple says will be encrypted just as they are on the iPhone or iPad.\n",
      "Apple also debuted a new feature called SharePlay that lets you bring music and shows into your FaceTime calls, allowing you to listen and watch with friends and family.\n",
      "Messages, meanwhile, is getting updates in the form of a feature called Shared with You, that allows you to view all of the news articles, and videos your friends have shared with you over time in your Messages, rather than losing them amidst your stream of back and forth texts.\n"
     ]
    }
   ],
   "source": [
    "# 문장비율 설정 요약\n",
    "print(summarize(news.text, ratio=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''이처럼 이준석 전 최고위원이 온라인에서 압도적 경쟁력을 보이고 있는 건 일찍부터 공을 들여왔기 때문이다.서울과학고와 하버드대를 졸업한 이공계 영재답게 각종 소셜미디어를 능수능란하게 활용해 왔다.\\ \n",
    "또한 진중권 전 동양대 교수와의 ‘온라인 배틀’에서 보듯이 여느 정치인이면 피했을 젠더 이슈에 적극적으로 뛰어들었다.\\ \n",
    "지난 21일에는 서울대 사회대 학생회가 주최한 토크 콘서트의 강연자로 나서 여성 징병제 등에 대해 학생들과 대화를 나누기도 했다.\\ \n",
    "일찍부터 암호화폐에 투자한 그는 ‘코인으로 얼마나 벌었냐’는 질문에 “선거를 몇 번 치를 정도로 벌었다”고 답하였다'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이처럼 이준석 전 최고위원이 온라인에서 압도적 경쟁력을 보이고 있는 건 일찍부터 공을 들여왔기 때문이다.서울과학고와 하버드대를 졸업한 이공계 영재답게 각종 소셜미디어를 능수능란하게 활용해 왔다.\\ \n"
     ]
    }
   ],
   "source": [
    "print(summarize(text, word_count=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
